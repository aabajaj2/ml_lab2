{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split(',')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "\n",
    "def selectJrand(i, m):\n",
    "    j = i  # we want to select any J not equal to i\n",
    "    while (j == i):\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j\n",
    "\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "\n",
    "def calcEkK(oS, k):\n",
    "    fXk = float(multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k, :].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "\n",
    "\n",
    "def selectJK(i, oS, Ei):  # this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    oS.eCache[i] = [1, Ei]  # set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:, 0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:  # loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if k == i: continue  # don't calc for i, waste of time\n",
    "            Ek = calcEkK(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEkK(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "\n",
    "def updateEkK(oS, k):  # after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEkK(oS, k)\n",
    "    oS.eCache[k] = [1, Ek]\n",
    "\n",
    "\n",
    "def innerLK(i, oS):\n",
    "    Ei = calcEkK(oS, i)\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or (\n",
    "                (oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j, Ej = selectJK(i, oS, Ei)  # this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy();\n",
    "        alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H: print(\"L==H\"); return 0\n",
    "        eta = 2.0 * oS.X[i, :] * oS.X[j, :].T - oS.X[i, :] * oS.X[i, :].T - oS.X[j, :] * oS.X[j, :].T\n",
    "        if eta >= 0: print(\"eta>=0\"); return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)\n",
    "        updateEkK(oS, j)  # added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): print(\"j not moving enough\"); return 0\n",
    "        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])  # update i by the same amount as j\n",
    "        updateEkK(oS, i)  # added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[i, :].T - oS.labelMat[j] * (\n",
    "            oS.alphas[j] - alphaJold) * oS.X[i, :] * oS.X[j, :].T\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i, :] * oS.X[j, :].T - oS.labelMat[j] * (\n",
    "            oS.alphas[j] - alphaJold) * oS.X[j, :] * oS.X[j, :].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class optStructK:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):  # Initialize the structure with the parameters\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m, 2)))  # first column is valid flag\n",
    "\n",
    "\n",
    "def smoPK(dataMatIn, classLabels, C, toler, maxIter):  # full Platt SMO\n",
    "    oS = optStructK(mat(dataMatIn), mat(classLabels).transpose(), C, toler)\n",
    "    iter = 0\n",
    "    entireSet = True;\n",
    "    alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:  # go over all\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerLK(i, oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:  # go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerLK(i, oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas\n",
    "\n",
    "\n",
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class svmClassifier:\n",
    "\n",
    "    def __init__(self, b, alphas, C, toler, maxIter):\n",
    "        self.b = b\n",
    "        self.alphas = alphas\n",
    "        self.C = C\n",
    "        self.toler = toler\n",
    "        self.maxIter = maxIter\n",
    "        self.weights = []\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.b, self.alphas = smoPK(X, Y, self.C, self.toler, self.maxIter)\n",
    "        self.weights = calcWs(alphas=self.alphas, dataArr=X, classLabels=Y)\n",
    "        print(\"Weights=\", self.weights)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        hypothesis = mat(x) * mat(self.weights) + self.b\n",
    "        return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L==H\n",
      "fullSet, iter: 0 i:0, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 0 i:1, pairs changed 0\n",
      "fullSet, iter: 0 i:2, pairs changed 1\n",
      "fullSet, iter: 0 i:3, pairs changed 1\n",
      "fullSet, iter: 0 i:4, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:5, pairs changed 2\n",
      "fullSet, iter: 0 i:6, pairs changed 2\n",
      "L==H\n",
      "fullSet, iter: 0 i:7, pairs changed 2\n",
      "fullSet, iter: 0 i:8, pairs changed 3\n",
      "fullSet, iter: 0 i:9, pairs changed 3\n",
      "fullSet, iter: 0 i:10, pairs changed 3\n",
      "fullSet, iter: 0 i:11, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:12, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:13, pairs changed 4\n",
      "fullSet, iter: 0 i:14, pairs changed 4\n",
      "fullSet, iter: 0 i:15, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:16, pairs changed 4\n",
      "fullSet, iter: 0 i:17, pairs changed 4\n",
      "fullSet, iter: 0 i:18, pairs changed 5\n",
      "fullSet, iter: 0 i:19, pairs changed 5\n",
      "fullSet, iter: 0 i:20, pairs changed 5\n",
      "fullSet, iter: 0 i:21, pairs changed 5\n",
      "fullSet, iter: 0 i:22, pairs changed 5\n",
      "fullSet, iter: 0 i:23, pairs changed 5\n",
      "fullSet, iter: 0 i:24, pairs changed 5\n",
      "fullSet, iter: 0 i:25, pairs changed 5\n",
      "fullSet, iter: 0 i:26, pairs changed 5\n",
      "fullSet, iter: 0 i:27, pairs changed 5\n",
      "fullSet, iter: 0 i:28, pairs changed 5\n",
      "fullSet, iter: 0 i:29, pairs changed 5\n",
      "fullSet, iter: 0 i:30, pairs changed 5\n",
      "fullSet, iter: 0 i:31, pairs changed 5\n",
      "fullSet, iter: 0 i:32, pairs changed 5\n",
      "fullSet, iter: 0 i:33, pairs changed 5\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:34, pairs changed 5\n",
      "fullSet, iter: 0 i:35, pairs changed 5\n",
      "fullSet, iter: 0 i:36, pairs changed 5\n",
      "fullSet, iter: 0 i:37, pairs changed 5\n",
      "fullSet, iter: 0 i:38, pairs changed 5\n",
      "fullSet, iter: 0 i:39, pairs changed 5\n",
      "fullSet, iter: 0 i:40, pairs changed 5\n",
      "fullSet, iter: 0 i:41, pairs changed 5\n",
      "fullSet, iter: 0 i:42, pairs changed 5\n",
      "L==H\n",
      "fullSet, iter: 0 i:43, pairs changed 5\n",
      "fullSet, iter: 0 i:44, pairs changed 5\n",
      "fullSet, iter: 0 i:45, pairs changed 5\n",
      "fullSet, iter: 0 i:46, pairs changed 5\n",
      "fullSet, iter: 0 i:47, pairs changed 5\n",
      "fullSet, iter: 0 i:48, pairs changed 5\n",
      "fullSet, iter: 0 i:49, pairs changed 5\n",
      "fullSet, iter: 0 i:50, pairs changed 5\n",
      "fullSet, iter: 0 i:51, pairs changed 5\n",
      "fullSet, iter: 0 i:52, pairs changed 5\n",
      "fullSet, iter: 0 i:53, pairs changed 5\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:54, pairs changed 5\n",
      "fullSet, iter: 0 i:55, pairs changed 5\n",
      "fullSet, iter: 0 i:56, pairs changed 5\n",
      "fullSet, iter: 0 i:57, pairs changed 5\n",
      "fullSet, iter: 0 i:58, pairs changed 5\n",
      "fullSet, iter: 0 i:59, pairs changed 5\n",
      "fullSet, iter: 0 i:60, pairs changed 5\n",
      "fullSet, iter: 0 i:61, pairs changed 5\n",
      "fullSet, iter: 0 i:62, pairs changed 5\n",
      "fullSet, iter: 0 i:63, pairs changed 5\n",
      "fullSet, iter: 0 i:64, pairs changed 5\n",
      "fullSet, iter: 0 i:65, pairs changed 5\n",
      "fullSet, iter: 0 i:66, pairs changed 5\n",
      "fullSet, iter: 0 i:67, pairs changed 5\n",
      "fullSet, iter: 0 i:68, pairs changed 5\n",
      "fullSet, iter: 0 i:69, pairs changed 5\n",
      "fullSet, iter: 0 i:70, pairs changed 5\n",
      "fullSet, iter: 0 i:71, pairs changed 5\n",
      "fullSet, iter: 0 i:72, pairs changed 5\n",
      "fullSet, iter: 0 i:73, pairs changed 5\n",
      "fullSet, iter: 0 i:74, pairs changed 5\n",
      "fullSet, iter: 0 i:75, pairs changed 5\n",
      "fullSet, iter: 0 i:76, pairs changed 5\n",
      "fullSet, iter: 0 i:77, pairs changed 5\n",
      "fullSet, iter: 0 i:78, pairs changed 5\n",
      "fullSet, iter: 0 i:79, pairs changed 5\n",
      "fullSet, iter: 0 i:80, pairs changed 5\n",
      "fullSet, iter: 0 i:81, pairs changed 5\n",
      "fullSet, iter: 0 i:82, pairs changed 5\n",
      "fullSet, iter: 0 i:83, pairs changed 5\n",
      "fullSet, iter: 0 i:84, pairs changed 5\n",
      "fullSet, iter: 0 i:85, pairs changed 5\n",
      "fullSet, iter: 0 i:86, pairs changed 5\n",
      "fullSet, iter: 0 i:87, pairs changed 5\n",
      "fullSet, iter: 0 i:88, pairs changed 5\n",
      "fullSet, iter: 0 i:89, pairs changed 5\n",
      "fullSet, iter: 0 i:90, pairs changed 5\n",
      "fullSet, iter: 0 i:91, pairs changed 5\n",
      "fullSet, iter: 0 i:92, pairs changed 5\n",
      "fullSet, iter: 0 i:93, pairs changed 5\n",
      "fullSet, iter: 0 i:94, pairs changed 5\n",
      "fullSet, iter: 0 i:95, pairs changed 5\n",
      "fullSet, iter: 0 i:96, pairs changed 5\n",
      "fullSet, iter: 0 i:97, pairs changed 5\n",
      "fullSet, iter: 0 i:98, pairs changed 5\n",
      "fullSet, iter: 0 i:99, pairs changed 5\n",
      "iteration number: 1\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:0, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:4, pairs changed 0\n",
      "non-bound, iter: 1 i:7, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:8, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:11, pairs changed 0\n",
      "non-bound, iter: 1 i:18, pairs changed 0\n",
      "iteration number: 2\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:0, pairs changed 0\n",
      "fullSet, iter: 2 i:1, pairs changed 0\n",
      "fullSet, iter: 2 i:2, pairs changed 0\n",
      "fullSet, iter: 2 i:3, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:4, pairs changed 0\n",
      "fullSet, iter: 2 i:5, pairs changed 0\n",
      "fullSet, iter: 2 i:6, pairs changed 0\n",
      "fullSet, iter: 2 i:7, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:8, pairs changed 0\n",
      "fullSet, iter: 2 i:9, pairs changed 0\n",
      "fullSet, iter: 2 i:10, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:11, pairs changed 0\n",
      "fullSet, iter: 2 i:12, pairs changed 0\n",
      "fullSet, iter: 2 i:13, pairs changed 0\n",
      "fullSet, iter: 2 i:14, pairs changed 0\n",
      "fullSet, iter: 2 i:15, pairs changed 0\n",
      "fullSet, iter: 2 i:16, pairs changed 0\n",
      "fullSet, iter: 2 i:17, pairs changed 0\n",
      "fullSet, iter: 2 i:18, pairs changed 0\n",
      "fullSet, iter: 2 i:19, pairs changed 0\n",
      "fullSet, iter: 2 i:20, pairs changed 0\n",
      "fullSet, iter: 2 i:21, pairs changed 0\n",
      "fullSet, iter: 2 i:22, pairs changed 0\n",
      "fullSet, iter: 2 i:23, pairs changed 0\n",
      "fullSet, iter: 2 i:24, pairs changed 0\n",
      "fullSet, iter: 2 i:25, pairs changed 0\n",
      "fullSet, iter: 2 i:26, pairs changed 0\n",
      "fullSet, iter: 2 i:27, pairs changed 0\n",
      "fullSet, iter: 2 i:28, pairs changed 0\n",
      "fullSet, iter: 2 i:29, pairs changed 0\n",
      "fullSet, iter: 2 i:30, pairs changed 0\n",
      "fullSet, iter: 2 i:31, pairs changed 0\n",
      "fullSet, iter: 2 i:32, pairs changed 0\n",
      "fullSet, iter: 2 i:33, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:34, pairs changed 0\n",
      "fullSet, iter: 2 i:35, pairs changed 0\n",
      "fullSet, iter: 2 i:36, pairs changed 0\n",
      "fullSet, iter: 2 i:37, pairs changed 0\n",
      "fullSet, iter: 2 i:38, pairs changed 0\n",
      "fullSet, iter: 2 i:39, pairs changed 0\n",
      "fullSet, iter: 2 i:40, pairs changed 0\n",
      "fullSet, iter: 2 i:41, pairs changed 0\n",
      "fullSet, iter: 2 i:42, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:43, pairs changed 0\n",
      "fullSet, iter: 2 i:44, pairs changed 0\n",
      "fullSet, iter: 2 i:45, pairs changed 0\n",
      "fullSet, iter: 2 i:46, pairs changed 0\n",
      "fullSet, iter: 2 i:47, pairs changed 0\n",
      "fullSet, iter: 2 i:48, pairs changed 0\n",
      "fullSet, iter: 2 i:49, pairs changed 0\n",
      "fullSet, iter: 2 i:50, pairs changed 0\n",
      "fullSet, iter: 2 i:51, pairs changed 0\n",
      "fullSet, iter: 2 i:52, pairs changed 0\n",
      "fullSet, iter: 2 i:53, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:54, pairs changed 0\n",
      "fullSet, iter: 2 i:55, pairs changed 0\n",
      "fullSet, iter: 2 i:56, pairs changed 0\n",
      "fullSet, iter: 2 i:57, pairs changed 0\n",
      "fullSet, iter: 2 i:58, pairs changed 0\n",
      "fullSet, iter: 2 i:59, pairs changed 0\n",
      "fullSet, iter: 2 i:60, pairs changed 0\n",
      "fullSet, iter: 2 i:61, pairs changed 0\n",
      "fullSet, iter: 2 i:62, pairs changed 0\n",
      "fullSet, iter: 2 i:63, pairs changed 0\n",
      "fullSet, iter: 2 i:64, pairs changed 0\n",
      "fullSet, iter: 2 i:65, pairs changed 0\n",
      "fullSet, iter: 2 i:66, pairs changed 0\n",
      "fullSet, iter: 2 i:67, pairs changed 0\n",
      "fullSet, iter: 2 i:68, pairs changed 0\n",
      "fullSet, iter: 2 i:69, pairs changed 0\n",
      "fullSet, iter: 2 i:70, pairs changed 0\n",
      "fullSet, iter: 2 i:71, pairs changed 0\n",
      "fullSet, iter: 2 i:72, pairs changed 0\n",
      "fullSet, iter: 2 i:73, pairs changed 0\n",
      "fullSet, iter: 2 i:74, pairs changed 0\n",
      "fullSet, iter: 2 i:75, pairs changed 0\n",
      "fullSet, iter: 2 i:76, pairs changed 0\n",
      "fullSet, iter: 2 i:77, pairs changed 0\n",
      "fullSet, iter: 2 i:78, pairs changed 0\n",
      "fullSet, iter: 2 i:79, pairs changed 0\n",
      "fullSet, iter: 2 i:80, pairs changed 0\n",
      "fullSet, iter: 2 i:81, pairs changed 0\n",
      "fullSet, iter: 2 i:82, pairs changed 0\n",
      "fullSet, iter: 2 i:83, pairs changed 0\n",
      "fullSet, iter: 2 i:84, pairs changed 0\n",
      "fullSet, iter: 2 i:85, pairs changed 0\n",
      "fullSet, iter: 2 i:86, pairs changed 0\n",
      "fullSet, iter: 2 i:87, pairs changed 0\n",
      "fullSet, iter: 2 i:88, pairs changed 0\n",
      "fullSet, iter: 2 i:89, pairs changed 0\n",
      "fullSet, iter: 2 i:90, pairs changed 0\n",
      "fullSet, iter: 2 i:91, pairs changed 0\n",
      "fullSet, iter: 2 i:92, pairs changed 0\n",
      "fullSet, iter: 2 i:93, pairs changed 0\n",
      "fullSet, iter: 2 i:94, pairs changed 0\n",
      "fullSet, iter: 2 i:95, pairs changed 0\n",
      "fullSet, iter: 2 i:96, pairs changed 0\n",
      "fullSet, iter: 2 i:97, pairs changed 0\n",
      "fullSet, iter: 2 i:98, pairs changed 0\n",
      "fullSet, iter: 2 i:99, pairs changed 0\n",
      "iteration number: 3\n",
      "Weights= [[ 0.60134587]\n",
      " [-0.49197924]]\n",
      "Classifier after fit b= [[-0.22724174]] Alpha= [[ 0.04679988]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.00444691]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.18895572]\n",
      " [ 0.03915585]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.04235297]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.14979987]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "Hypothesis= [[ 2.30413053]\n",
      " [ 3.26703084]\n",
      " [-2.84058639]\n",
      " [-3.20857861]\n",
      " [-2.16351655]\n",
      " [ 1.96944632]\n",
      " [-2.73334437]\n",
      " [ 1.        ]\n",
      " [-2.35391285]\n",
      " [ 1.71778708]\n",
      " [-2.41994641]\n",
      " [-1.30525436]\n",
      " [ 2.52235412]\n",
      " [ 2.63516945]\n",
      " [-1.63608615]\n",
      " [-2.59265565]\n",
      " [ 2.19813383]\n",
      " [-1.96670548]\n",
      " [-1.        ]\n",
      " [ 2.40017618]\n",
      " [ 2.47990397]\n",
      " [ 1.78231453]\n",
      " [ 1.35566024]\n",
      " [-2.28665816]\n",
      " [ 2.47267448]\n",
      " [ 3.02271411]\n",
      " [-1.72149052]\n",
      " [-2.39159944]\n",
      " [-1.724361  ]\n",
      " [-1.18886749]\n",
      " [-3.03329783]\n",
      " [ 1.85977708]\n",
      " [-2.02201441]\n",
      " [ 2.97147374]\n",
      " [-0.95995644]\n",
      " [-2.53913277]\n",
      " [-1.02857356]\n",
      " [-1.32721508]\n",
      " [-2.23623279]\n",
      " [ 2.68093004]\n",
      " [ 2.91346164]\n",
      " [ 2.09510231]\n",
      " [-1.61256661]\n",
      " [ 0.76146373]\n",
      " [-1.57255569]\n",
      " [-1.62422258]\n",
      " [ 1.45971642]\n",
      " [ 1.08588477]\n",
      " [-2.02957704]\n",
      " [-2.75039468]\n",
      " [-2.68775665]\n",
      " [-2.68602956]\n",
      " [ 2.0770791 ]\n",
      " [-1.89648857]\n",
      " [-0.90278227]\n",
      " [-1.15250767]\n",
      " [ 1.5744284 ]\n",
      " [ 2.77339867]\n",
      " [ 2.28253294]\n",
      " [-1.44772809]\n",
      " [ 2.19892711]\n",
      " [ 1.76300091]\n",
      " [-2.56861385]\n",
      " [ 2.57790716]\n",
      " [ 2.02961701]\n",
      " [ 2.20112328]\n",
      " [-3.6907599 ]\n",
      " [-1.08561879]\n",
      " [-1.65080798]\n",
      " [ 2.68266629]\n",
      " [ 3.5485531 ]\n",
      " [ 2.93676817]\n",
      " [-2.03514568]\n",
      " [ 1.17574474]\n",
      " [-2.41266188]\n",
      " [ 2.47162922]\n",
      " [-1.79667136]\n",
      " [ 2.11216759]\n",
      " [-2.12436229]\n",
      " [ 2.54881179]\n",
      " [-1.46623377]\n",
      " [ 2.07061752]\n",
      " [ 1.81534198]\n",
      " [-1.77584877]\n",
      " [ 1.95460422]\n",
      " [-2.75539668]\n",
      " [-1.76721063]\n",
      " [ 2.13942129]\n",
      " [ 1.84889679]\n",
      " [-2.87713773]\n",
      " [-2.19225139]\n",
      " [-3.01824109]\n",
      " [ 3.27504445]\n",
      " [-1.79342758]\n",
      " [ 2.47871363]\n",
      " [ 1.85568578]\n",
      " [ 2.46287204]\n",
      " [ 2.17534857]\n",
      " [ 2.60437401]\n",
      " [ 1.94454033]]\n"
     ]
    }
   ],
   "source": [
    "dataMatrix, labelMat = loadDataSet('data/linearly_separable.csv')\n",
    "clf = svmClassifier(b=None, alphas=None, C=200, toler=0.0001, maxIter=1000)\n",
    "clf = clf.fit(dataMatrix, labelMat)\n",
    "print(\"Classifier after fit\", \"b=\",  clf.b, \"Alpha=\", clf.alphas)\n",
    "hyp = clf.predict(dataMatrix)\n",
    "print(\"Hypothesis=\", hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fit(fit_line, datamatrix, labelmatrix):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    weights = fit_line\n",
    "\n",
    "    dataarray = np.asarray(datamatrix)\n",
    "    n = dataarray.shape[0]\n",
    "\n",
    "    # Keep track of the two classes in different arrays so they can be plotted later...\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    xcord2 = []\n",
    "    ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelmatrix[i]) == 1:\n",
    "            xcord1.append(dataarray[i, 0])\n",
    "            ycord1.append(dataarray[i, 1])\n",
    "        else:\n",
    "            xcord2.append(dataarray[i, 0])\n",
    "            ycord2.append(dataarray[i, 1])\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Plot the data as points with different colours\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')\n",
    "    ax.scatter(xcord2, ycord2, s=30, c='green')\n",
    "\n",
    "    # Plot the best-fit line\n",
    "    x = np.arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0] - weights[1] * x) / weights[2]\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = []\n",
    "line.append(clf.b.getA()[0])\n",
    "line.append(clf.weights[0])\n",
    "line.append(clf.weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x172288a7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fit(line, dataMatrix, labelMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
